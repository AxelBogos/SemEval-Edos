# -*- coding: utf-8 -*-
"""self-training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19yUkXYrtc7AOrkZLDMJN9pzSm_mkdVaD
"""

import pandas as pd
import os

unlabeled_reddit0 = pd.read_csv(os.path.join("./data/", "df_0reddit.csv"))
unlabeled_reddit1 = pd.read_csv(os.path.join("./data/", "df_1reddit.csv"))
unlabeled_reddit2 = pd.read_csv(os.path.join("./data/", "df_2reddit.csv"))
# unlabeled_reddit3 = pd.read_csv(os.path.join("./data/", "df_3reddit.csv"))
# unlabeled_reddit4 = pd.read_csv(os.path.join("./data/", "df_4reddit.csv"))

unlabeled_GAB0 = pd.read_csv(os.path.join("./data/", "df_0GAB.csv"))
unlabeled_GAB1 = pd.read_csv(os.path.join("./data/", "df_1GAB.csv"))
unlabeled_GAB2 = pd.read_csv(os.path.join("./data/", "df_2GAB.csv"))
unlabeled_GAB3 = pd.read_csv(os.path.join("./data/", "df_3GAB.csv"))
unlabeled_GAB4 = pd.read_csv(os.path.join("./data/", "df_4GAB.csv"))

unlabeled_data = pd.concat([
    unlabeled_GAB0,
    unlabeled_GAB1,
    unlabeled_GAB2,
    unlabeled_GAB3,
    unlabeled_GAB4,
    unlabeled_reddit0,
    unlabeled_reddit1,
    unlabeled_reddit2
    ])

# Shuffle the rows of the dataframe and return 35%
# unlabeled_data = unlabeled_data.sample(frac=0.5).reset_index(drop=True)

unlabeled_data_text = unlabeled_data['text'].tolist()

unlabeled_data.rename(columns={unlabeled_data.columns[0]: "text" }, inplace = True)
unlabeled_data_text = unlabeled_data['text'].tolist()

import wandb
run = wandb.init()
artifact = run.use_artifact('jiebao637/EDOS-ift6289/model-tots9oce:v0', type='model')
artifact_dir = artifact.download()

import torch
from transformers import RobertaConfig, RobertaForSequenceClassification

# Replace 'path_to_config_json' with the path to your config.json file
config = RobertaConfig.from_json_file('./config-distilroberta.json')

# Load the model weights from the 'model.ckpt' file
pl_checkpoint = torch.load('./artifacts/model-tots9oce:v0/model.ckpt')

# Extract the model state_dict
state_dict = pl_checkpoint['state_dict']

config.num_labels = 2
config.type_vocab_size = 1

# Remove 'model.' prefix from state_dict keys
state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
filtered_state_dict = {k: v for k, v in state_dict.items() if k != 'criterion.weight'}

# Initialize the model with the configuration and state_dict
model = RobertaForSequenceClassification(config)
model.load_state_dict(filtered_state_dict)

import numpy as np
from transformers import RobertaTokenizer
from tqdm import tqdm

tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')

# # Example unlabeled data
# unlabeled_data = [
#     "This movie was amazing!",
#     "The film was terrible and boring.",
#     "I really enjoyed the storyline and the acting.",
#     "[USER] Leg day is easy. Hot girls who wear miniskirts get asked out."
# ]

# Tokenize and create a tensor for the input
inputs = [tokenizer(text, return_tensors="pt", padding=True, truncation=True) for text in tqdm(unlabeled_data_text)]

# Move input tensors to the GPU, if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
inputs = [{key: tensor.to(device) for key, tensor in input.items()} for input in inputs]

# Generate predictions (logits)
logits = []
with torch.no_grad():
    for input in tqdm(inputs):
        logits.append(model(**input).logits)

# Convert logits to probabilities
probs = [torch.softmax(logit, dim=1).cpu().numpy() for logit in tqdm(logits)]
probs = np.concatenate(probs, axis=0)

# Set a confidence threshold for pseudo-labeling
confidence_threshold = 0.95

# Get the most confident predictions and their indices
most_confident_indices = np.where(probs.max(axis=1) > confidence_threshold)[0]
most_confident_preds = probs.argmax(axis=1)[most_confident_indices]

len(most_confident_indices)

probs[:10]

most_confident_indices[:10]

most_confident_preds[:10]

unlabeled_data_text

pd.DataFrame(probs).to_csv("probs_task_a_FULL_distil_roberta.csv", index=False)
pd.DataFrame(unlabeled_data_text).to_csv("unlabeled_data_FULL_distil_roberta.csv", index=False)

##################################################################################

import wandb
run = wandb.init()
artifact = run.use_artifact('jiebao637/EDOS-ift6289/model-unfbjets:v0', type='model')
artifact_dir = artifact.download()

# Replace 'path_to_config_json' with the path to your config.json file
config = RobertaConfig.from_json_file('./config-distilroberta.json')

# Load the model weights from the 'model.ckpt' file
pl_checkpoint = torch.load('./artifacts/model-unfbjets:v0/model.ckpt')

# Extract the model state_dict
state_dict = pl_checkpoint['state_dict']

config.num_labels = 4
config.type_vocab_size = 1

# Remove 'model.' prefix from state_dict keys
state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
filtered_state_dict = {k: v for k, v in state_dict.items() if k != 'criterion.weight'}

# Initialize the model with the configuration and state_dict
model = RobertaForSequenceClassification(config)
model.load_state_dict(filtered_state_dict)

unlabeled_data_text = pd.read_csv("task_b_distilroberta.csv")['text'].tolist()

import numpy as np
from transformers import RobertaTokenizer
from tqdm import tqdm

tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')

# # Example unlabeled data
# unlabeled_data = [
#     "This movie was amazing!",
#     "The film was terrible and boring.",
#     "I really enjoyed the storyline and the acting.",
#     "[USER] Leg day is easy. Hot girls who wear miniskirts get asked out."
# ]

# Tokenize and create a tensor for the input
inputs = [tokenizer(text, return_tensors="pt", padding=True, truncation=True) for text in tqdm(unlabeled_data_text)]

# Move input tensors to the GPU, if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
inputs = [{key: tensor.to(device) for key, tensor in input.items()} for input in inputs]

# Generate predictions (logits)
logits = []
with torch.no_grad():
    for input in tqdm(inputs):
        logits.append(model(**input).logits)

# Convert logits to probabilities
probs = [torch.softmax(logit, dim=1).cpu().numpy() for logit in tqdm(logits)]
probs = np.concatenate(probs, axis=0)

probs[0]

pd.DataFrame(probs).to_csv("probs_task_b_FULL_distil_roberta.csv", index=False)
pd.DataFrame(unlabeled_data_text).to_csv("unlabeled_data_FULL_distil_roberta.csv", index=False)

##################################################################################

import wandb
run = wandb.init()
artifact = run.use_artifact('jiebao637/EDOS-ift6289/model-pbsqt0y6:v0', type='model')
artifact_dir = artifact.download()

# Replace 'path_to_config_json' with the path to your config.json file
config = RobertaConfig.from_json_file('./config-distilroberta.json')

# Load the model weights from the 'model.ckpt' file
pl_checkpoint = torch.load('./artifacts/model-pbsqt0y6:v0/model.ckpt')

# Extract the model state_dict
state_dict = pl_checkpoint['state_dict']

config.num_labels = 11
config.type_vocab_size = 1

# Remove 'model.' prefix from state_dict keys
state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
filtered_state_dict = {k: v for k, v in state_dict.items() if k != 'criterion.weight'}

# Initialize the model with the configuration and state_dict
model = RobertaForSequenceClassification(config)
model.load_state_dict(filtered_state_dict)

unlabeled_data_text = pd.read_csv("task_b_distilroberta.csv")['text'].tolist()

tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')

# # Example unlabeled data
# unlabeled_data = [
#     "This movie was amazing!",
#     "The film was terrible and boring.",
#     "I really enjoyed the storyline and the acting.",
#     "[USER] Leg day is easy. Hot girls who wear miniskirts get asked out."
# ]

# Tokenize and create a tensor for the input
inputs = [tokenizer(text, return_tensors="pt", padding=True, truncation=True) for text in tqdm(unlabeled_data_text)]

# Move input tensors to the GPU, if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
inputs = [{key: tensor.to(device) for key, tensor in input.items()} for input in inputs]

# Generate predictions (logits)
logits = []
with torch.no_grad():
    for input in tqdm(inputs):
        logits.append(model(**input).logits)

# Convert logits to probabilities
probs = [torch.softmax(logit, dim=1).cpu().numpy() for logit in tqdm(logits)]
probs = np.concatenate(probs, axis=0)

# Set a confidence threshold for pseudo-labeling
confidence_threshold = 0.8

# Get the most confident predictions and their indices
most_confident_indices = np.where(probs.max(axis=1) > confidence_threshold)[0]
most_confident_preds = probs.argmax(axis=1)[most_confident_indices]

probs[0]

len(most_confident_preds)

pd.DataFrame(probs).to_csv("probs_task_c_FULL_distil_roberta.csv", index=False)

##################################################################################

import wandb
run = wandb.init()
artifact = run.use_artifact('jiebao995/EDOS-ift6289/model-ywwvk7yj:v1', type='model')
artifact_dir = artifact.download()

import torch
from transformers import RobertaConfig, RobertaForSequenceClassification

# Replace 'path_to_config_json' with the path to your config.json file
config = RobertaConfig.from_json_file('./config_task_b.json')

# Load the model weights from the 'model.ckpt' file
pl_checkpoint = torch.load('./artifacts/model-ywwvk7yj:v1/model.ckpt')

# Extract the model state_dict
state_dict = pl_checkpoint['state_dict']

import pandas as pd
unlabeled_task_b_reddit_FULL = pd.read_csv("unlabeled_task_b_gab_FULL.csv")
# unlabeled_task_b_reddit = pd.read_csv("unlabeled_task_b_reddit.csv")

config.num_labels = 4
config.type_vocab_size = 1

# Remove 'model.' prefix from state_dict keys
state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
filtered_state_dict = {k: v for k, v in state_dict.items() if k != 'criterion.weight'}

# Initialize the model with the configuration and state_dict
model = RobertaForSequenceClassification(config)
model.load_state_dict(filtered_state_dict)

import numpy as np
from transformers import RobertaTokenizer
from tqdm import tqdm

tokenizer = RobertaTokenizer.from_pretrained('roberta-large')

# # Example unlabeled data
# unlabeled_data = [
#     "This movie was amazing!",
#     "The film was terrible and boring.",
#     "I really enjoyed the storyline and the acting.",
#     "[USER] Leg day is easy. Hot girls who wear miniskirts get asked out."
# ]

# Tokenize and create a tensor for the input
# inputs = [tokenizer(text, return_tensors="pt", padding=True, truncation=True) for text in tqdm(unlabeled_task_b_GAB_FULL['text'].tolist())]

# Move input tensors to the GPU, if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
inputs = [{key: tensor.to(device) for key, tensor in input.items()} for input in inputs]

# Generate predictions (logits)
logits = []
with torch.no_grad():
    for input in tqdm(inputs):
        logits.append(model(**input).logits)

# Convert logits to probabilities
probs = [torch.softmax(logit, dim=1).cpu().numpy() for logit in tqdm(logits)]
probs = np.concatenate(probs, axis=0)

probs1 = pd.read_csv("probs_task_b.csv")
np.array(probs1)

probs

# Set a confidence threshold for pseudo-labeling
confidence_threshold = 0.8

# Get the most confident predictions and their indices
most_confident_indices = np.where(probs.max(axis=1) > confidence_threshold)[0]
most_confident_preds = probs.argmax(axis=1)[most_confident_indices]

len(most_confident_indices)

unique_values, counts = np.unique(most_confident_preds, return_counts=True)

for value, count in zip(unique_values, counts):
    print(f"{value}: {count}")
    # reddit

unique_values, counts = np.unique(most_confident_preds, return_counts=True)

for value, count in zip(unique_values, counts):
    print(f"{value}: {count}")
    # gab

unique_values, counts = np.unique(most_confident_preds, return_counts=True)

for value, count in zip(unique_values, counts):
    print(f"{value}: {count}")
    # gab

pd.DataFrame(probs).to_csv("probs_task_b_GAB_FULL.csv", index=False)

##################################################################################
import wandb
run = wandb.init()
artifact = run.use_artifact('jiebao637/EDOS-ift6289/model-kofn768l:v0', type='model')
artifact_dir = artifact.download()

import torch
from transformers import DistilBertConfig, DistilBertForSequenceClassification

# Replace 'path_to_config_json' with the path to your config.json file
config = DistilBertConfig.from_json_file('./config-distilbert-task-c.json')

# Load the model weights from the 'model.ckpt' file
pl_checkpoint = torch.load('./artifacts/model-kofn768l:v0/model.ckpt')

# Extract the model state_dict
state_dict = pl_checkpoint['state_dict']

import pandas as pd
unlabeled_task_b_gab_FULL = pd.read_csv("unlabeled_task_b_gab_FULL.csv")
unlabeled_task_b_reddit = pd.read_csv("unlabeled_task_b_reddit.csv")

config.num_labels = 11
config.type_vocab_size = 1

# Remove 'model.' prefix from state_dict keys
state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
filtered_state_dict = {k: v for k, v in state_dict.items() if k != 'criterion.weight'}

# Initialize the model with the configuration and state_dict
model = DistilBertForSequenceClassification(config)
model.load_state_dict(filtered_state_dict)

unlabeled_task_c = pd.concat([unlabeled_task_b_gab_FULL, unlabeled_task_b_reddit])

import numpy as np
from transformers import DistilBertTokenizer
from tqdm import tqdm

tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

# # Example unlabeled data
# unlabeled_data = [
#     "This movie was amazing!",
#     "The film was terrible and boring.",
#     "I really enjoyed the storyline and the acting.",
#     "[USER] Leg day is easy. Hot girls who wear miniskirts get asked out."
# ]

# Tokenize and create a tensor for the input
inputs = [tokenizer(text, return_tensors="pt", padding=True, truncation=True) for text in tqdm(unlabeled_task_c['text'].tolist())]

# Move input tensors to the GPU, if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
inputs = [{key: tensor.to(device) for key, tensor in input.items()} for input in inputs]

# Generate predictions (logits)
logits = []
with torch.no_grad():
    for input in tqdm(inputs):
        logits.append(model(**input).logits)

# Convert logits to probabilities
probs = [torch.softmax(logit, dim=1).cpu().numpy() for logit in tqdm(logits)]
probs = np.concatenate(probs, axis=0)

# Set a confidence threshold for pseudo-labeling
confidence_threshold = 0.9

# Get the most confident predictions and their indices
most_confident_indices = np.where(probs.max(axis=1) > confidence_threshold)[0]
most_confident_preds = probs.argmax(axis=1)[most_confident_indices]

unique_values, counts = np.unique(most_confident_preds, return_counts=True)

for value, count in zip(unique_values, counts):
    print(f"{value}: {count}")

probs[0]

pd.DataFrame(probs).to_csv("probs_task_c_FULL.csv", index=False)